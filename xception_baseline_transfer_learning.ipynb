{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "xception-baseline-transfer-learning.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vovaekb/kaggle_severstal_xception_transfer_learning/blob/master/xception_baseline_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "id": "3Ey3XPcjnQPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm_notebook\n",
        "import cv2\n",
        "from tensorflow.python.keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.color import gray2rgb\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras.layers import UpSampling2D, Conv2D, Activation, Conv2DTranspose\n",
        "from keras import Model\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
        "from keras.applications.xception import preprocess_input\n",
        "from imgaug import augmenters as iaa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bJQh-MpanQQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 8 # 16 # 4 # 64 # 128 # 8\n",
        "EPOCHS = 80 # 95\n",
        "IMG_SIZE = 256\n",
        "\n",
        "train_dir = '../input/severstal-steel-defect-detection/train_images'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3KRVVt17nQQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "    def __init__(self, list_ids, image_dir, batch_size=32,\n",
        "                 img_h=256, img_w=256, shuffle=False):\n",
        "        \n",
        "        self.list_ids = list_ids\n",
        "        self.image_dir = image_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.img_h = img_h\n",
        "        self.img_w = img_w\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "    \n",
        "    def __len__(self):\n",
        "        'denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_ids)) / self.batch_size)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        'generate one batch of data'\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        # get list of IDs\n",
        "        list_ids_temp = [self.list_ids[k] for k in indexes]\n",
        "        # generate data\n",
        "        \n",
        "        X, y = self.__data_generation(list_ids_temp)\n",
        "#         X = self.augmentor(X)\n",
        "        # return data \n",
        "        return X, y\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        'update ended after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_ids))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "            \n",
        "    def __data_generation(self, list_ids_temp):\n",
        "        'generate data containing batch_size samples'\n",
        "        X = np.empty((self.batch_size, self.img_h, self.img_w, 3))\n",
        "        y = np.empty((self.batch_size, self.img_h, self.img_w, 1))\n",
        "        \n",
        "        for idx, id in enumerate(list_ids_temp):\n",
        "            file_path =  os.path.join(self.image_dir, id)\n",
        "            \n",
        "            image = cv2.imread(file_path, 1)\n",
        "            image_resized = cv2.resize(image, (self.img_w, self.img_h))\n",
        "            image_resized = np.array(image_resized, dtype=np.float64)\n",
        "            \n",
        "            '''\n",
        "            image = self.__load_grayscale(file_path)\n",
        "            \n",
        "            # Store samples\n",
        "            image_resized = gray2rgb(image[:,:,0])\n",
        "            '''\n",
        "                        \n",
        "            mask = np.empty((self.img_h, self.img_w, 1))\n",
        "            \n",
        "            rle_name = id + '_' + '4'\n",
        "            rle = df_train[df_train['ImageId_ClassId'] == rle_name]['EncodedPixels'].values[0]\n",
        "            \n",
        "            class_mask = rle_to_mask(rle, width=1600, height=256) \n",
        "            class_mask_resized = cv2.resize(class_mask, (self.img_w, self.img_h))\n",
        "            mask = class_mask_resized\n",
        "            \n",
        "            X[idx,] = image_resized\n",
        "            y[idx,] = np.expand_dims(mask, -1)\n",
        "        \n",
        "#         X = self.augmentor(X)\n",
        "        \n",
        "        # normalize \n",
        "        X = X / 255\n",
        "        y = (y > 0).astype(int)\n",
        "            \n",
        "        return X, y\n",
        "    \n",
        "    def __load_grayscale(self, img_path):\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.resize(img, (self.img_w, self.img_h))\n",
        "        img = img.astype(np.float32) / 255.\n",
        "        img = np.expand_dims(img, axis=-1)\n",
        "\n",
        "        return img\n",
        "    \n",
        "    def augmentor(self, images):\n",
        "        'Apply data augmentation'\n",
        "        sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "        seq = iaa.Sequential(\n",
        "            [\n",
        "                iaa.Sharpen((0.0, 1.0)),       # sharpen the image\n",
        "                iaa.Fliplr(),\n",
        "                iaa.Flipud(),\n",
        "                iaa.ElasticTransformation(alpha=50, sigma=5)\n",
        "                ],random_order=True\n",
        "        )\n",
        "        return seq.augment_images(images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CIq4utApnQRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv('../input/severstal-steel-defect-detection/train.csv')\n",
        "print(len(df_train))\n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "U00A7XzYnQRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'Only 4 class'\n",
        "df_train = df_train[df_train['EncodedPixels'].notnull()].reset_index(drop=True)\n",
        "df_train = df_train[df_train['ImageId_ClassId'].apply(lambda x: x.split('_')[1] == '4')].reset_index(drop=True)\n",
        "print(len(df_train))\n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GLR4UM_znQRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train['ImageId'] = df_train['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
        "listdir = df_train['ImageId'].values\n",
        "train, valid = train_test_split(listdir, train_size=0.8)\n",
        "print(train[:2], valid[:2])\n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2QgkwSlCnQRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rle_to_mask(rle_string, height, width):\n",
        "    \n",
        "    rows, cols = height, width\n",
        "    img = np.zeros(rows * cols, dtype=np.uint8)\n",
        "    if len(str(rle_string)) > 1:\n",
        "        rle_numbers = [int(numstring) for numstring in rle_string.split(' ')]\n",
        "        rle_pairs = np.array(rle_numbers).reshape(-1, 2)\n",
        "        for index, length in rle_pairs:\n",
        "            index -= 1\n",
        "            img[index:index+length] = 255\n",
        "    else: img = np.zeros(cols*rows)\n",
        "    img = img.reshape(cols, rows)\n",
        "    img = img.T\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "b4aLQagQnQR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x, y in DataGenerator(df_train['ImageId'], \n",
        "                          '../input/severstal-steel-defect-detection/train_images', \n",
        "                          batch_size=32, img_h=256, img_w=256, shuffle=True):\n",
        "    break\n",
        "    \n",
        "print(x.shape, y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "i11yIEPVnQSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(np.squeeze(x[3]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HFpUrFiYnQSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(np.squeeze(y[3]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HCdoiTkCnQSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'metric and loss function for evaluation'\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2 * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def loss_dice_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return -K.log((2 * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ABX6bc5UnQS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'load pretrained model'\n",
        "from keras.applications import Xception\n",
        "base_model = Xception(weights=None, input_shape=(IMG_SIZE,IMG_SIZE,3), include_top=False)\n",
        "base_model.load_weights('../input/keras-pretrained-models/xception_weights_tf_dim_ordering_tf_kernels_notop.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "IuZd0r77nQS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TTA5o0lTnQTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_out = base_model.output # (8, 8)\n",
        "conv1 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (base_out) # (8, 16, 16)\n",
        "up = UpSampling2D(8, interpolation='bilinear')(conv1) # (8, 128, 128)\n",
        "conv2 = Conv2DTranspose(1, (2, 2), strides=(2, 2), padding='same') (up) # (1, 256, 256)\n",
        "conv3 = Conv2D(1, (1, 1))(conv2)\n",
        "conv4 = Activation('sigmoid')(conv3)\n",
        "\n",
        "lr=1e-5 # 1e-4 # 0.0001 # 1e-2 # 1e-3\n",
        "model = Model(input=base_model.input, output=conv4)\n",
        "optimizer = keras.optimizers.RMSprop(lr=lr) # keras.optimizers.Adam(lr=lr) # keras.optimizers.Adam(lr=lr, decay=1e-6) #  # , decay = 1e-6\n",
        "model.compile(optimizer=optimizer, loss=loss_dice_coef, metrics=[dice_coef]) # decay = 1e-6\n",
        "\n",
        "# model.summary()\n",
        "# for i, layer in enumerate(base_model.layers):\n",
        "#     print(\"{} {}\".format(i, layer.__class__.__name__))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Ac2qUqS7nQTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_generator = DataGenerator(train, train_dir, batch_size=BATCH_SIZE, shuffle=True)\n",
        "train_size = len(train)\n",
        "print(train_size)\n",
        "\n",
        "val_generator = DataGenerator(valid, train_dir, batch_size=BATCH_SIZE)\n",
        "train_size = len(valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0649CEUnQTQ",
        "colab_type": "text"
      },
      "source": [
        "We use ModelCheckpoint and ReduceLROnPlateau callbacks. ModelCheckpoint monitors the loss metric  after each epoch and prints out whether the metric has improved. ReduceLROnPlateau reduces learning rate when a metric has stopped improving during a number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4bOkfcA9nQTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, # factor=0.1 #0.2\n",
        "                                      patience=5, min_lr=1e-6) # min_lr=1e-5 # 0.000001 # 0.0001\n",
        "\n",
        "# Add model checkpoint\n",
        "checkpoint = ModelCheckpoint(\"model_out.hdf5\", monitor=\"val_loss\", verbose=1, save_best_only=True)\n",
        "\n",
        "es = EarlyStopping(monitor=\"loss\", mode=\"min\", verbose=1, patience=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aEpBN0ERnQTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "history = model.fit_generator(generator=train_generator,\n",
        "                              validation_data=val_generator,\n",
        "                              epochs=EPOCHS, # 15, # 20\n",
        "#                               steps_per_epoch=train_size//BATCH_SIZE,\n",
        "                              callbacks=[checkpoint, reduce_lr], # , es\n",
        "                              verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fYspU6vAnQTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "# unfreeze the final set of CONV layers and make them trainable\n",
        "for layer in base_model.layers[122:]: # 122 - 3 last Conv layers (Conv2D) # 126 - 2 last Conv layers (SeparableConv2D's) # 129\n",
        "    layer.trainable = True\n",
        "\n",
        "lr=1e-2 # 1e-3 # 0.01 # 0.001\n",
        "# optimizer = keras.optimizers.RMSprop(lr=lr) # keras.optimizers.Adam(lr=lr) # keras.optimizers.Adam(lr=lr) #  # \n",
        "model.compile(optimizer=optimizer, loss=loss_dice_coef, metrics=[dice_coef]) # 0.0001\n",
        "# '''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UT-_rUdAnQTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "%%time\n",
        "history = model.fit_generator(generator=train_generator, epochs=90, # 50, # 35, # 5 #EPOCHS, \n",
        "                              steps_per_epoch=train_size//BATCH_SIZE,\n",
        "                              callbacks=[reduce_lr, checkpoint, es],\n",
        "                              verbose=1, shuffle=True)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uoKn3sLwnQT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "plt.plot(np.arange(len(history.history['loss'])) + 1, history.history['loss'], label='loss')\n",
        "plt.plot(np.arange(len(history.history['val_loss'])) + 1, history.history['val_loss'], label='val_loss')\n",
        "\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "S0EDl9tYnQT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict(x)\n",
        "plt.imshow(np.squeeze(pred[3] > 0.5).astype(int))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ilI97_3ZnQUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testfiles=os.listdir(\"../input/severstal-steel-defect-detection/test_images/\")\n",
        "len(testfiles)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "dlJECJMqnQUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "test_img = []\n",
        "for fn in tqdm_notebook(testfiles):\n",
        "        img = cv2.imread( '../input/severstal-steel-defect-detection/test_images/'+fn )\n",
        "        img = cv2.resize(img,(IMG_SIZE, IMG_SIZE))       \n",
        "        test_img.append(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Oqg2P43rnQUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "predict = model.predict(np.array(test_img))\n",
        "print(len(predict))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Pw1NkZyonQUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mask_to_rle(mask):\n",
        "    '''\n",
        "    Convert a mask into RLE\n",
        "    \n",
        "    Parameters: \n",
        "    mask (numpy.array): binary mask of numpy array where 1 - mask, 0 - background\n",
        "\n",
        "    Returns: \n",
        "    sring: run length encoding \n",
        "    '''\n",
        "    pixels= mask.T.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "U8LHDCcWnQUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "pred_rle = []\n",
        "for img in tqdm_notebook(predict):\n",
        "    img = cv2.resize(img, (1600, 256))\n",
        "    tmp = np.copy(img)\n",
        "    tmp[tmp<0.5] = 0\n",
        "    tmp[tmp>0] = 1\n",
        "    pred_rle.append(mask_to_rle(tmp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "O9Y32cjPnQUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_t = cv2.imread( '../input/severstal-steel-defect-detection/test_images/'+ testfiles[4])\n",
        "plt.imshow(img_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fcitF-yUnQUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask_t = rle_to_mask(pred_rle[4], 256, 1600)\n",
        "plt.imshow(mask_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HBerKXaYnQUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub = pd.read_csv( '../input/severstal-steel-defect-detection/sample_submission.csv', converters={'EncodedPixels': lambda e: ' '} )\n",
        "sub.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "OYZbK0wsnQU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "for fn, rle in zip(testfiles, pred_rle):\n",
        "    sub['EncodedPixels'][(sub['ImageId_ClassId'].apply(lambda x: x.split('_')[0]) == fn) & \\\n",
        "                        (sub['ImageId_ClassId'].apply(lambda x: x.split('_')[1] == '4'))] = rle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lKScdgAvnQVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_s = cv2.imread( '../input/severstal-steel-defect-detection/test_images/'+ sub['ImageId_ClassId'][47].split('_')[0])\n",
        "plt.imshow(img_s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jJKqcZ31nQVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask_s = rle_to_mask(sub['EncodedPixels'][47], 256, 1600)\n",
        "plt.imshow(mask_s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "E9-ahIT5nQVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}